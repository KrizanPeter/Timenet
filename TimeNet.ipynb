{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\" #4번 DEVICES만 사용하여 다른 메모리를 낭비를 방지\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "#costomized seq2seq cell\n",
    "import copy\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops import variable_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#=======================================Hyperparameter \n",
    "learning_rate = 0.001\n",
    "total_epoch = 1000\n",
    "batch_size = 100 \n",
    "dropout = 0.5\n",
    "hidden_size = 200\n",
    "index = 0\n",
    "\n",
    "feed_train = {}\n",
    "feed_val = {}\n",
    "outputs = []\n",
    "targets = []\n",
    "DATAS = []\n",
    "data_size = 50\n",
    "\n",
    "#훈련에 사용할 데이터 이름을 배열로 저장한다. \n",
    "traindatasets = ['Plane', 'GunPoint', 'ArrowHead', 'WordSynonyms', 'ToeSegmentation1', 'FISH', 'ShapeletSim', 'ShapesAll', 'SonyAIBORobotSurface1',\n",
    "             'Lightning7', 'ToeSegmentation2', 'DiatomSizeReduction', 'Ham', 'SonyAIBORobotSurface2', 'TwoLeadECG', 'FacesUCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_rnn_seq2seq(encoder_inputs,\n",
    "                          decoder_inputs,\n",
    "                          cell,\n",
    "                          dtype=dtypes.float32,\n",
    "                          scope=None):\n",
    "    \n",
    "    with variable_scope.variable_scope(scope or \"basic_rnn_seq2seq\"):\n",
    "        enc_cell = copy.deepcopy(cell)\n",
    "        encoder_outputs, enc_state = tf.contrib.rnn.static_rnn(enc_cell, encoder_inputs, dtype=dtype)\n",
    "    return customized_rnn_decoder(encoder_outputs, decoder_inputs, enc_state, cell)\n",
    "\n",
    "def customized_rnn_decoder(encoder_outputs,\n",
    "                decoder_inputs,\n",
    "                initial_state,\n",
    "                cell,\n",
    "                loop_function=None,\n",
    "                scope=None):\n",
    "    \n",
    "    with variable_scope.variable_scope(scope or \"rnn_decoder\"):\n",
    "        state = initial_state\n",
    "        outputs = []\n",
    "        prev = None\n",
    "        for i, inp in enumerate(decoder_inputs):\n",
    "            if loop_function is not None and prev is not None:\n",
    "                with variable_scope.variable_scope(\"loop_function\", reuse=True):\n",
    "                    inp = loop_function(prev, i)\n",
    "            if i > 0:\n",
    "                variable_scope.get_variable_scope().reuse_variables()\n",
    "            output, state = cell(inp, state)\n",
    "            outputs.append(output)\n",
    "            if loop_function is not None:\n",
    "                prev = output\n",
    "    return encoder_outputs, outputs, state\n",
    "\n",
    "def data_maker(dataset):\n",
    "    print(dataset)\n",
    "    #train 숫자가 너무 작아서 concatenate이후 train_test_split를 이용해 다시 나눈다.\n",
    "    datadir = 'UCRArchive_2018' + '/' + dataset + '/' + dataset\n",
    "    data_train = np.loadtxt(datadir+'_TRAIN.tsv', delimiter='\\t')\n",
    "    data_test = np.loadtxt(datadir+'_TEST.tsv', delimiter='\\t')\n",
    "    DATA = np.concatenate((data_train,data_test),axis=0)\n",
    "    \n",
    "    #특정 데이터의 y lable이 1부터 시작해 range error 발생.첫 인덱스가 1이면 1을 빼서 0으로 만듬\n",
    "    X_data = DATA[:,1:]\n",
    "    y_data = DATA[:,[0]]\n",
    "    y_first_index = int(np.unique(y_data)[0])\n",
    "    if int(y_first_index) == 1:\n",
    "        y_data = DATA[:,[0]]-1\n",
    "    DATA = np.concatenate((y_data, X_data), axis=1)\n",
    "    \n",
    "    #50행마다 잘라서 DATAS 배열에 저정\n",
    "    iter = DATA.shape[0]//data_size\n",
    "    for i in range(iter):\n",
    "        CUT_DATA = DATA[50*i:50*(i+1),:]\n",
    "        DATAS.append(CUT_DATA)\n",
    "    \n",
    "def seq2seq_maker(index, DATA):\n",
    "\n",
    "    X_data = DATA[:,1:]\n",
    "    y_data = DATA[:,0]\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=1)\n",
    "    \n",
    "    encoder_input = tf.placeholder(tf.float32, [None, X_train.shape[1]]) \n",
    "    decoder_input = tf.placeholder(tf.float32, [None, X_train.shape[1]])\n",
    "    target = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "    targets.append(target)\n",
    "    \n",
    "    with tf.variable_scope(\"rnn_\"+str(index)):\n",
    "        cell = tf.contrib.rnn.GRUCell(num_units=hidden_size)\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=0.5)\n",
    "        #output, states = tf.contrib.legacy_seq2seq.basic_rnn_seq2seq([encoder_input], [decoder_input], cell)\n",
    "        en_outputs, de_outputs, state = customized_rnn_seq2seq([encoder_input], [decoder_input], cell)\n",
    "        #print(\"encoder_outputs\", encoder_outputs)\n",
    "        #print(\"decoder_outputs\", decoder_outputs)\n",
    "        de_outputs = tf.reshape(de_outputs, [-1, hidden_size]) #3D -> 2D\n",
    "        outputs.append(de_outputs)\n",
    "    \n",
    "    feed_train[encoder_input] = X_train\n",
    "    feed_train[decoder_input] = X_train\n",
    "    feed_train[target] = y_train\n",
    "    \n",
    "    feed_val[encoder_input] = X_val\n",
    "    feed_val[decoder_input] = X_val\n",
    "    feed_val[target] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plane\n",
      "GunPoint\n",
      "ArrowHead\n",
      "WordSynonyms\n",
      "ToeSegmentation1\n",
      "FISH\n",
      "ShapeletSim\n",
      "ShapesAll\n",
      "SonyAIBORobotSurface1\n",
      "Lightning7\n",
      "ToeSegmentation2\n",
      "DiatomSizeReduction\n",
      "Ham\n",
      "SonyAIBORobotSurface2\n",
      "TwoLeadECG\n",
      "FacesUCR\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-85b1fee72b4a>:71: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-3-85b1fee72b4a>:9: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\kriza\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kriza\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\kriza\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "#data_maker('Plane')        \n",
    "for dataset in traindatasets:\n",
    "    data_maker(dataset)    \n",
    "    \n",
    "for index, DATA in enumerate(DATAS):\n",
    "    seq2seq_maker(index, DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W <tf.Variable 'W:0' shape=(200, 100) dtype=float32_ref>\n",
      "b <tf.Variable 'b:0' shape=(100,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([hidden_size, 100]), name=\"W\") \n",
    "b = tf.Variable(tf.random_normal([100]), name=\"b\") #최대 클래수의 갯수인 60보다는 커야 range 에러 안생김\n",
    "print(\"W\", W)\n",
    "print(\"b\", b)\n",
    "logits = [tf.matmul(output, W) + b for output in outputs]\n",
    "\n",
    "with tf.variable_scope(\"cost\"):\n",
    "    loss = []\n",
    "    for logit, target in zip(logits, targets):\n",
    "        loss.append(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logit, labels=target))\n",
    "    #cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=targets))\n",
    "    cost= tf.reduce_mean(loss)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost) \n",
    "    \n",
    "#with tf.variable_scope(\"eval\"):\n",
    "#    prediction = tf.argmax(tf.nn.softmax(logits), 1) \n",
    "#    correct_prediction = tf.equal(prediction, targets)#one-hot을 안쓰면 target에는 argmax할 필요없음\n",
    "#    accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.7752874   2.0469844   0.36769435 ... -0.8887142  -0.39307138\n",
      "  -0.18026935]\n",
      " [ 0.35898998  1.1710458  -0.5539473  ...  1.610424   -0.3653937\n",
      "   0.2267573 ]\n",
      " [ 1.7162745   3.4374948   0.18480867 ... -0.33494365 -0.70481473\n",
      "   1.5762633 ]\n",
      " ...\n",
      " [ 1.0546646   2.1506813  -1.7801001  ... -0.08220769  1.5439498\n",
      "   1.8349516 ]\n",
      " [-2.4351687   1.5379708  -0.27892506 ... -2.2651443   0.2654991\n",
      "   0.12807518]\n",
      " [ 0.6646134   0.41552642 -1.6548251  ... -0.5516775   0.41803804\n",
      "   0.48632395]]\n",
      "[ 1.0229144   0.10713756  1.2602333  -0.18442847  1.0593863   0.5241448\n",
      "  0.38003686  2.0510676   0.34854162 -0.46839184 -1.3516546  -1.2927005\n",
      "  0.2775945   0.45241794  1.7855079   0.1428486   2.197832   -0.05300001\n",
      "  0.56384265 -0.3621135   1.0877128   1.0643741  -1.7113878  -1.8861148\n",
      "  0.49191344 -1.0251831  -1.8322444  -0.19497852 -0.0093414   0.5123816\n",
      " -0.63917947  0.29399693 -0.3947946  -0.03477793 -0.22016911  0.18740991\n",
      " -0.6377595  -0.6909403   1.8086764   0.1957868   1.1917068   0.3121187\n",
      "  0.5106586  -1.4103146  -1.4999449  -2.7044766   0.66161746 -0.10199916\n",
      " -0.02279397  1.2707777   0.8595847  -0.51078475  0.9622572  -0.88360846\n",
      " -0.7098269  -1.4913269  -1.0287327  -0.40101263 -1.0951536  -0.25585675\n",
      " -0.92576957  0.13322021  0.9284341   0.09194557  0.2886534  -1.099663\n",
      " -0.11733882  0.6584703  -0.49212244  1.378654    0.31270203 -0.50857097\n",
      " -1.8607545  -0.6103319  -1.0786191  -1.5422686   0.13954127 -1.4184303\n",
      "  2.0137646  -0.07396756  0.11858455 -1.0129801  -0.0852141  -0.78480124\n",
      " -0.49538723  1.0627272  -0.99274904 -0.14849328  0.6173164   1.992241\n",
      "  0.02163593 -0.27713823 -0.76058984 -0.95922816 -0.055263    1.8076211\n",
      "  1.1680217   1.7386084   0.6248893  -0.45595476]\n",
      "============================sess init\n",
      "Epoch 1/1000 took 22.463s\n",
      "  Train      loss : 11.244384\n",
      "  Validation loss : 7.637080\n",
      "Epoch 101/1000 took 119.846s\n",
      "  Train      loss : 0.028829\n",
      "  Validation loss : 0.010004\n",
      "Epoch 201/1000 took 214.565s\n",
      "  Train      loss : 0.015267\n",
      "  Validation loss : 0.003248\n",
      "Epoch 301/1000 took 310.703s\n",
      "  Train      loss : 0.014238\n",
      "  Validation loss : 0.003447\n",
      "Epoch 401/1000 took 399.636s\n",
      "  Train      loss : 0.011515\n",
      "  Validation loss : 0.001041\n",
      "Epoch 501/1000 took 485.415s\n",
      "  Train      loss : 0.011743\n",
      "  Validation loss : 0.003120\n",
      "Epoch 601/1000 took 571.559s\n",
      "  Train      loss : 0.013560\n",
      "  Validation loss : 0.006549\n",
      "Epoch 701/1000 took 658.144s\n",
      "  Train      loss : 0.006831\n",
      "  Validation loss : 0.000316\n",
      "Epoch 801/1000 took 744.314s\n",
      "  Train      loss : 0.012175\n",
      "  Validation loss : 0.000659\n",
      "Epoch 901/1000 took 830.318s\n",
      "  Train      loss : 0.010657\n",
      "  Validation loss : 0.001352\n",
      "It took 915.647173166275 seconds to train for 1000 epochs.\n",
      "============================ training end\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.7284567   2.05269     0.40483415 ... -0.854966   -0.34325504\n",
      "  -0.17232311]\n",
      " [ 0.43552798  1.1929252  -0.6938882  ...  1.5337152  -0.3543816\n",
      "   0.23690172]\n",
      " [ 1.773098    3.3432832   0.16986354 ... -0.319354   -0.69197303\n",
      "   1.5099975 ]\n",
      " ...\n",
      " [ 1.1676127   2.0779474  -1.6909802  ... -0.12395951  1.4972156\n",
      "   1.7547349 ]\n",
      " [-2.4309518   1.5244138  -0.22376706 ... -2.2099066   0.2634362\n",
      "   0.14904453]\n",
      " [ 0.74781716  0.47769055 -1.6354996  ... -0.5439584   0.37198693\n",
      "   0.44186816]]\n",
      "[ 1.0554953   0.13200715  1.3497628  -0.08985579  1.1039551   0.62838703\n",
      "  0.49179208  2.0151026   0.38626596 -0.44754857 -1.3280872  -1.2626417\n",
      "  0.30824035  0.42201585  1.7576851   0.08711861  2.1643758  -0.08977063\n",
      "  0.48551452 -0.42499292  1.0428873   1.0349277  -1.706072   -1.8644013\n",
      "  0.46023548 -1.0863844  -1.9255868  -0.2376011  -0.04339891  0.48300266\n",
      " -0.7015836   0.2553724  -0.44430754 -0.10291735 -0.22453512  0.1131088\n",
      " -0.69227767 -0.7583144   1.7773801   0.14792427  1.1550161   0.26683602\n",
      "  0.4637513  -1.4010204  -1.5364369  -2.709004    0.6236347  -0.14254941\n",
      " -0.07510329  1.2362667   0.8105213  -0.5168585   0.90746397 -0.9474326\n",
      " -0.77479404 -1.5118256  -1.0669345  -0.44030607 -1.1187457  -0.3071534\n",
      " -1.0039461   0.0961572   0.88942784  0.04019678  0.22918472 -1.1486409\n",
      " -0.16407056  0.6142365  -0.5249104   1.3383527   0.25740412 -0.5412852\n",
      " -1.9061799  -0.65827847 -1.1084657  -1.5678357   0.10442393 -1.4639344\n",
      "  1.9732627  -0.10625295  0.08332054 -1.0816444  -0.11672574 -0.82152164\n",
      " -0.54723656  1.0205927  -1.0655004  -0.22056992  0.58126706  1.9594476\n",
      " -0.02396396 -0.3405546  -0.7939039  -1.0017889  -0.08688965  1.7660254\n",
      "  1.1402603   1.7034152   0.58756953 -0.5106724 ]\n",
      "model saved!\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    print(sess.run(\"W:0\"))\n",
    "    print(sess.run(\"b:0\"))\n",
    "    print(\"============================sess init\")\n",
    "    start_time = time.time()\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in range(total_epoch):\n",
    "        _, tr_loss = sess.run([optimizer, cost], feed_dict = feed_train)\n",
    "        _, va_loss = sess.run([optimizer, cost], feed_dict = feed_val)\n",
    "        train_losses += [tr_loss]\n",
    "        valid_losses += [va_loss]\n",
    "        if epoch % 100 == 0:  \n",
    "            print(\"Epoch {}/{} took {:.3f}s\".format(epoch + 1, total_epoch,time.time() - start_time))\n",
    "            print(\"  Train      loss : %.6f\"%(train_losses[epoch]))\n",
    "            print(\"  Validation loss : %.6f\"%(valid_losses[epoch]))\n",
    "    print(\"It took\", time.time() - start_time, \"seconds to train for\", total_epoch, \"epochs.\")        \n",
    "    print(\"============================ training end\")\n",
    "    \n",
    "    #loss  그래프를 확인한다. \n",
    "    plt.plot(train_losses, '-b', label='Train loss')\n",
    "    plt.plot(valid_losses, '-r', label='Valid loss')\n",
    "    plt.legend(loc=0)\n",
    "    plt.title('Loss graph')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    #print('Accuracy:', sess.run(accuracy_op, feed_dict=feed_dict))\n",
    "    \n",
    "    #pred = sess.run(prediction, feed_dict=feed_dict)\n",
    "    #for p, i in zip(pred, y_test.flatten()):\n",
    "    #    print(\"[{}] Prediction: {} True Y: {}\".format(p == int(i), p, int(i)))\n",
    "        \n",
    "    print(sess.run(\"W:0\"))\n",
    "    print(sess.run(\"b:0\"))\n",
    "    save_path = saver.save(sess, \"./180123.ckpt\")\n",
    "    print(\"model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "saver = tf.train.import_meta_graph(\"./180123.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-abece4611618>:34: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\kriza\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\legacy_seq2seq\\python\\ops\\seq2seq.py:186: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\kriza\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kriza\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:565: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\kriza\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:575: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "outputs Tensor(\"seq2seqCoffee/Reshape:0\", shape=(?, 200), dtype=float32)\n",
      "states Tensor(\"seq2seqCoffee/basic_rnn_seq2seq/rnn_decoder/gru_cell/add:0\", shape=(?, 200), dtype=float32)\n",
      "W Tensor(\"W:0\", shape=(200, 100), dtype=float32_ref)\n",
      "b Tensor(\"b:0\", shape=(100,), dtype=float32_ref)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = 0.001\n",
    "total_epoch = 1000\n",
    "batch_size = 100 \n",
    "dropout = 0.5\n",
    "hidden_size = 200\n",
    "index = 0\n",
    "\n",
    "dataset = 'Coffee'\n",
    "datadir = 'UCRArchive_2018' + '/' + dataset + '/' + dataset\n",
    "data_train = np.loadtxt(datadir+'_TRAIN.tsv', delimiter='\\t')\n",
    "data_test = np.loadtxt(datadir+'_TEST.tsv', delimiter='\\t')\n",
    "\n",
    "#train 숫자가 너무 작아서 concatenate이후 train_test_split를 이용해 다시 나눈다.\n",
    "DATA = np.concatenate((data_train,data_test),axis=0)\n",
    "X_data_n = DATA[:,1:]\n",
    "y_data_n = DATA[:,0]\n",
    "\n",
    "#특정 데이터의 y lable이 1부터 시작해 range error 발생.첫 인덱스가 1이면 1을 빼서 0으로 만듬\n",
    "y_first_index = int(np.unique(y_data_n)[0])\n",
    "if int(y_first_index) == 1:\n",
    "    y_data_n = DATA[:,0]-1\n",
    "\n",
    "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(X_data_n, y_data_n, test_size=0.2, random_state=1)\n",
    "X_train_n, X_val_n, y_train_n, y_val_n = train_test_split(X_train_n, y_train_n, test_size=0.2, random_state=1)\n",
    "\n",
    "n_variable = X_train_n.shape[1]\n",
    "\n",
    "# placeholder\n",
    "encoder_inputs = tf.placeholder(tf.float32, [None, n_variable], name=\"encoder_inputs\")\n",
    "decoder_inputs = tf.placeholder(tf.float32, [None, n_variable], name=\"decoder_inputs\")\n",
    "targets = tf.placeholder(tf.int64, [None], name=\"targets\")\n",
    "\n",
    "with tf.variable_scope(\"seq2seq\"+dataset):  \n",
    "    cell = tf.contrib.rnn.GRUCell(num_units=hidden_size)\n",
    "    outputs, states = tf.contrib.legacy_seq2seq.basic_rnn_seq2seq([encoder_inputs], [decoder_inputs], cell)\n",
    "    outputs = tf.reshape(outputs, [-1, hidden_size]) #3D -> 2D\n",
    "    print(\"outputs\", outputs)  # output 모양이 항상 [? , hidden_size]으로 고정됨\n",
    "    print(\"states\", states)\n",
    "    \n",
    "    \n",
    "    W = tf.get_default_graph().get_tensor_by_name(\"W:0\")\n",
    "    b = tf.get_default_graph().get_tensor_by_name(\"b:0\")\n",
    "    print(\"W\", W)\n",
    "    print(\"b\", b)\n",
    "    logits = tf.matmul(outputs, W) + b\n",
    "\n",
    "with tf.variable_scope(\"cost\"+dataset):\n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=targets))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost) \n",
    "\n",
    "#print(optimizer)\n",
    "    \n",
    "with tf.variable_scope(\"eval\"+dataset):\n",
    "    prediction = tf.argmax(tf.nn.softmax(logits), 1) \n",
    "    correct_prediction = tf.equal(prediction, targets)#one-hot을 안쓰면 target에는 argmax할 필요없음\n",
    "    accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./180123.ckpt\n",
      "... check point loaded\n",
      "[[ 2.2213447   0.3219719   0.490732   ...  0.4942872   0.83331865\n",
      "   2.3464181 ]\n",
      " [ 0.9293427  -0.5835477  -0.60782105 ... -0.7719066   0.09963955\n",
      "   0.48788664]\n",
      " [-0.6694349  -0.43705964  0.8162472  ... -1.2734629   1.355652\n",
      "   0.48305488]\n",
      " ...\n",
      " [-1.0361733   0.13412148  0.30746385 ... -1.0050983   0.26483974\n",
      "  -0.40772647]\n",
      " [ 0.58828133  0.6410695  -1.0061091  ... -0.98361045  0.06794253\n",
      "   0.02531427]\n",
      " [-0.769398   -1.3087723   0.00831522 ... -0.22830899  0.42123502\n",
      "  -0.62423563]]\n",
      "[ 2.6085396  -0.13781853  0.5079586   0.7505565  -1.6711701  -1.1244154\n",
      " -1.2220967  -0.9417593  -0.75413495  0.7835153   0.76824826  0.01421006\n",
      " -0.84674037 -0.36326706 -0.89012754  1.6949654  -0.17451143 -0.17321901\n",
      "  0.25079346  0.96105075 -0.19576448  0.18262634 -0.04339788 -0.44675002\n",
      "  0.03818896 -0.5850081   0.45266193  0.30945715 -0.03430903  0.50403404\n",
      "  0.3875951   0.7881022  -0.9923665   1.1446277   0.35451147 -0.78186536\n",
      "  0.2636655  -0.6810216   0.48509568 -1.1281995   1.0134664  -0.6925074\n",
      " -0.4657965  -0.2842264  -0.19420502 -0.64189523  0.1927023  -1.1930281\n",
      "  0.4399041  -1.1250904   0.82068926  1.9889681   0.5169783   1.7859102\n",
      " -1.7405604  -1.4908129   1.2667551   0.20525137 -1.1473598  -1.1852242\n",
      "  0.6606851   0.7973213  -0.21778503  0.93277043  1.4845728  -1.7786216\n",
      "  0.69635725 -0.6914711  -0.59305555  0.27201623 -1.5651445  -0.3422639\n",
      "  0.69554144 -2.868164   -1.4379076  -0.55696255 -1.6639522   1.8667883\n",
      " -0.978083   -0.29593268 -0.60559607 -0.58895946 -1.2846706   0.32581523\n",
      " -0.21133175 -0.03026143 -0.07387211  0.47515836 -0.30159453  1.1795429\n",
      "  0.42657632 -0.20892018  0.9405378  -0.7922269  -2.6546562   0.20845534\n",
      "  1.7034365  -0.35825625  0.342946    0.23999697]\n",
      "=============================== training Coffee\n",
      "Epoch 1/1000 took 1.819s\n",
      "  Train loss : 4.535911\n",
      "  valid loss : 0.770093\n",
      "Epoch 101/1000 took 3.109s\n",
      "  Train loss : 0.004867\n",
      "  valid loss : 0.001603\n",
      "Epoch 201/1000 took 4.379s\n",
      "  Train loss : 0.001556\n",
      "  valid loss : 0.000423\n",
      "Epoch 301/1000 took 5.641s\n",
      "  Train loss : 0.000553\n",
      "  valid loss : 0.000166\n",
      "Epoch 401/1000 took 6.913s\n",
      "  Train loss : 0.000236\n",
      "  valid loss : 0.000078\n",
      "Epoch 501/1000 took 8.187s\n",
      "  Train loss : 0.000130\n",
      "  valid loss : 0.000051\n",
      "Epoch 601/1000 took 9.450s\n",
      "  Train loss : 0.000108\n",
      "  valid loss : 0.000037\n",
      "Epoch 701/1000 took 10.708s\n",
      "  Train loss : 0.000074\n",
      "  valid loss : 0.000025\n",
      "Epoch 801/1000 took 11.969s\n",
      "  Train loss : 0.000066\n",
      "  valid loss : 0.000017\n",
      "Epoch 901/1000 took 13.229s\n",
      "  Train loss : 0.000053\n",
      "  valid loss : 0.000013\n",
      "============================ training end\n",
      "Accuracy: 1.0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "new_saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver.restore(sess, \"./180123.ckpt\")\n",
    "    print(\"... check point loaded\")\n",
    "    print(sess.run(\"W:0\"))\n",
    "    print(sess.run(\"b:0\"))\n",
    "    print(\"=============================== training\", dataset)\n",
    "    start_time = time.time()\n",
    "    # 비용함수을 학습시킨다. \n",
    "    for epoch in range(total_epoch):\n",
    "        #Minibatch \n",
    "        batch_mask = np.random.choice(len(X_train_n), batch_size)\n",
    "        X_batch = X_train_n[batch_mask]\n",
    "        y_batch = y_train_n[batch_mask]\n",
    "\n",
    "        # Compute the losses, 훈련을 통해 w,b가 계속 조정되고 그로 인해 변하는 정확성이나 비용함수를 측정하는 것\n",
    "        _, tr_loss = sess.run([optimizer, cost], feed_dict={encoder_inputs: X_batch, decoder_inputs: X_batch, targets: y_batch})\n",
    "        _, val_loss = sess.run([optimizer, cost], feed_dict={encoder_inputs: X_val_n, decoder_inputs: X_val_n,targets: y_val_n})\n",
    "        # Log the losses\n",
    "        train_losses += [tr_loss]\n",
    "        val_losses += [val_loss]\n",
    "  \n",
    "        if epoch % 100 == 0:  \n",
    "            print(\"Epoch {}/1000 took {:.3f}s\".format(epoch + 1, time.time() - start_time))\n",
    "            print(\"  Train loss : %.6f\"%(train_losses[epoch]))\n",
    "            print(\"  valid loss : %.6f\"%(val_losses[epoch]))\n",
    "\n",
    "    print(\"============================ training end\")\n",
    "    print('Accuracy:', sess.run(accuracy_op, feed_dict={encoder_inputs: X_test_n, decoder_inputs: X_test_n, targets: y_test_n}))\n",
    "    \n",
    "    pred = sess.run(prediction, feed_dict={encoder_inputs: X_test_n, decoder_inputs: X_test_n})\n",
    "    for p, i in zip(pred, y_test_n.flatten()):\n",
    "        print(\"[{}] Prediction: {} True Y: {}\".format(p == int(i), p, int(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
